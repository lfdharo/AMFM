#settings .yaml
#author : ' vanmaren'
#description: yaml file for confirating paramaters for Training process
#interesting parameters: for jp right now implemented


###############################################################
test:
  DATASET_DIR: JPO_PATENT_org/jp_zh/tokext # IITB/newtry ASPEC/en_jp ASPEC/jp_zh CharTokenizationForTa ENTA/NotCharTokenization        WithCharTokenizationForHI
  FULL_AM_SIZE: 2500 # Max size of the trained AM model
  OPT_AM_SIZE: 600 # Optimal value for the trained AM model 2000
  NUM_TRAINING_SIZE: 10000  # 10000 20000 Number of sentences used during training
  PREFIX_AM_FM: 'train' # 'train'  Prefix for the AM-FM models
  NGRAM_ORDER: 3 # Order the FM score calculation
  NUM_FOLD: 0 # Number of Folds
  alpha: 0.9  # Interpolation value for AM-FM
  ModelsDir: /home/enrique/Escritorio/TFG_Pendrive/AMFM/AMFM_TFG2018/Test/models #Dir where the Models will be placed
  TestDir: /home/enrique/Escritorio/TFG_Pendrive/AMFM/AMFM_TFG2018/Test #Dir for the test
  preProcess: True

